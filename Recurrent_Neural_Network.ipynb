{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recurrent Neural Network.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "IBgK7F7KQgcQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.contrib import rnn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9Mj579UvQgcY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "udMNMR7OQgce",
        "colab_type": "code",
        "outputId": "d00d0a81-899e-4287-b6a2-c48c54d1de29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "cell_type": "code",
      "source": [
        "mnist=input_data.read_data_sets(\"/temp/data/\",one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-16d542ecb6a4>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /temp/data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /temp/data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting /temp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /temp/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9wN1vZtMQgcj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hm_epoch=20\n",
        "n_classes=10\n",
        "batch_size=128\n",
        "\n",
        "chunk_size=28\n",
        "n_chunk=28\n",
        "rnn_size=128\n",
        "\n",
        "x=tf.placeholder('float')\n",
        "y=tf.placeholder('float')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "StieRevWQgco",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def recurrent_neural_network(x):\n",
        "    layer={'weights':tf.Variable(tf.random_normal([rnn_size,n_classes])),\n",
        "           'biases':tf.Variable(tf.random_normal([n_classes]))}\n",
        "    \n",
        "    x=tf.transpose(x,[1,0,2])\n",
        "    x=tf.reshape(x,[-1,chunk_size])\n",
        "    x=tf.split(x,n_chunk,0)\n",
        "    lstm_cell=rnn.BasicLSTMCell(rnn_size)\n",
        "    \n",
        "    outputs,states=rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
        "    \n",
        "    \n",
        "    \n",
        "    output=tf.matmul(outputs[-1],layer['weights']) + layer['biases']\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5ugopUQ9Qgct",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_neural_network(x):\n",
        "    prediction=recurrent_neural_network(x)\n",
        "    cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction,labels=y))\n",
        "    \n",
        "    optimizer=tf.train.AdamOptimizer().minimize(cost)\n",
        "    \n",
        "    \n",
        "    with tf.Session() as ses:\n",
        "        ses.run(tf.global_variables_initializer())\n",
        "        for epoch in range(hm_epoch):\n",
        "            epoch_loss=0\n",
        "            for _ in range(int(mnist.train.num_examples/(batch_size))):\n",
        "                a,b=mnist.train.next_batch(batch_size)\n",
        "                a=a.reshape((batch_size,n_chunk,chunk_size))\n",
        "                k,c=ses.run([optimizer,cost],feed_dict={x:a,y:b})\n",
        "                epoch_loss+=c\n",
        "            print(\"epoch\",epoch+1,\"completed out of\",hm_epoch,\"loss=\",epoch_loss)\n",
        "        correct=tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))\n",
        "        accuracy=tf.reduce_mean(tf.cast(correct,'float'))\n",
        "        print(\"accuracy:\",accuracy.eval({x:mnist.test.images.reshape((-1,n_chunk,chunk_size)),y:mnist.test.labels}))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3LZSgW3gQo-t",
        "colab_type": "code",
        "outputId": "a73fd163-8de7-4023-ecaf-b44115f87534",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "cell_type": "code",
      "source": [
        "train_neural_network(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-5-0d0e144bbc4b>:8: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
            "epoch 1 completed out of 20 loss= 201.84075710177422\n",
            "epoch 2 completed out of 20 loss= 56.19226348772645\n",
            "epoch 3 completed out of 20 loss= 37.891395254060626\n",
            "epoch 4 completed out of 20 loss= 28.90676971990615\n",
            "epoch 5 completed out of 20 loss= 23.34244318958372\n",
            "epoch 6 completed out of 20 loss= 20.51301548955962\n",
            "epoch 7 completed out of 20 loss= 17.2661659817677\n",
            "epoch 8 completed out of 20 loss= 15.323859017342329\n",
            "epoch 9 completed out of 20 loss= 13.334140933468007\n",
            "epoch 10 completed out of 20 loss= 11.843687708023936\n",
            "epoch 11 completed out of 20 loss= 10.821219510457013\n",
            "epoch 12 completed out of 20 loss= 10.032655305694789\n",
            "epoch 13 completed out of 20 loss= 8.231231992162066\n",
            "epoch 14 completed out of 20 loss= 8.13208215899067\n",
            "epoch 15 completed out of 20 loss= 7.625391316018067\n",
            "epoch 16 completed out of 20 loss= 6.391635974490782\n",
            "epoch 17 completed out of 20 loss= 7.141432925243862\n",
            "epoch 18 completed out of 20 loss= 5.063595981860999\n",
            "epoch 19 completed out of 20 loss= 4.826989851426333\n",
            "epoch 20 completed out of 20 loss= 5.7651779318694025\n",
            "accuracy: 0.9841\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s8YoD2gFRCyd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}